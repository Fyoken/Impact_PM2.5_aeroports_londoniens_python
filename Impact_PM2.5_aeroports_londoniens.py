# -*- coding: utf-8 -*-
"""

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gXOpCeoptxwV1dLeCCSCan245xi8DEZV
"""

from google.colab import drive
import pandas as pd
import numpy as np

#drive.mount('/content/gdrive')

df_lung = pd.read_csv("./cancer_patient.csv")
df_PM = pd.read_csv("./particulate-air-pollution-mortality.csv")
df_mental = pd.read_csv("./air_pollution_on_mental_health.csv")

"""# Data exploration : l'impact des PM2.5 en zones aéroportuaires sur les morts londoniennes"""

import pandas as pd
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 3))
plt.hist(df_PM['Total Population'][1:], bins=20, edgecolor='black', alpha=0.7)
plt.xlabel('Population Totale')
plt.ylabel('Fréquence')
plt.title('Distribution de la population totale dans différentes zones de Londres')
plt.grid(True)
plt.show()

# Créer un histogramme de la concentration de PM2.5 par zone
plt.figure(figsize=(5, 3))
plt.hist(df_PM['PM2.5 Concentration (µg/m3)'], bins=20, edgecolor='black', alpha=0.7)
plt.xlabel('Concentration de PM2.5 (µg/m3)')
plt.ylabel('Fréquence')
plt.title('Distribution de la concentration de PM2.5 dans les différentes zones de Londres')
plt.grid(True)
plt.show()

# Coefficients de variation à comparer
coefficients = ['Attributable Deaths at coefft (change for 10 µg/m3 PM2.5) 1%',
                'Attributable Deaths at coefft (change for 10 µg/m3 PM2.5) 6%',
                'Attributable Deaths at coefft (change for 10 µg/m3 PM2.5) 12%']

# Calculer les moyennes et les écarts types des décès attribuables pour chaque coefficient
means = [df_PM[coeff].mean() for coeff in coefficients]
std_devs = [df_PM[coeff].std() for coeff in coefficients]

# Créer un graphique à barres avec des barres d'erreur
x = np.arange(len(coefficients))
width = 0.35

plt.figure(figsize=(5, 3))
plt.bar(x, means, width, yerr=std_devs, capsize=5)
plt.xlabel('Coefficient de Variation')
plt.ylabel('Nb moyen décès attribuables')
plt.title('Comparaison des décès attribuables à différents coefficients de variation')
plt.xticks(x, ['coefft 1%', 'coefft 6%', 'coefft 12%'])
plt.tight_layout()
plt.show()

"""# Étude sur l'impact des PM2.5 en zones aéroportuaires sur les morts londoniennes"""

print(df_PM['Area Name'])
# Liste des noms d'aéroports de Londres
noms_aeroports_londres = [
    "Heathrow Villages",
]

"""On remarque une très forte corrélation entre la concentration en PM2.5 et le nombre de morts attribuables en pourcentage, aux PM2.5."""

import numpy as np

class AirQualitySystem:
    def __init__(self, pm25_data):
        self.pm25_data = pm25_data
        self.aqi_categories = {
            0: {'name': 'perfect', 'pollution': 1},
            50: {'name': 'good', 'pollution': 2},
            100: {'name': 'moderate', 'pollution': 3},
            150: {'name': 'unhealthy for sensitive groups', 'pollution': 4},
            200: {'name': 'unhealthy', 'pollution': 5},
            300: {'name': 'very unhealthy', 'pollution': 6},
            400: {'name': 'dangerous', 'pollution': 7},
            500: {'name': 'very dangerous', 'pollution': 8}
        }
        self.thresholds = list(self.aqi_categories.keys())  # Using thresholds directly

    def calculate_aqi(self, pm25):
        breakpoints = [0.1, 14.5, 14.75, 15, 15.25, 15.5, 16, 17]
        aqi_breakpoints = [0.1, 50, 100, 150, 200, 300, 400, 500]

        for i in range(1, len(breakpoints)):
            if pm25 <= breakpoints[i]:
                aqi = (aqi_breakpoints[i - 1] + (aqi_breakpoints[i] - aqi_breakpoints[i - 1]) *
                             (np.log(pm25) - np.log(breakpoints[i - 1])) / (np.log(breakpoints[i]) - np.log(breakpoints[i - 1])))
                return min(aqi, 500)  # Cap AQI at 500 (maximum value)
        return 500  # If PM2.5 concentration exceeds the highest breakpoint

    def get_aqi_category(self, aqi):
        for threshold, category in sorted(self.aqi_categories.items()):
            if aqi <= threshold:
                return category
        # Return the highest category if AQI exceeds the highest threshold
        return self.aqi_categories[max(self.aqi_categories.keys())]

    def check_air_quality(self):
        aqi_categories = [self.get_aqi_category(self.calculate_aqi(pm25))['name'] for pm25 in self.pm25_data]
        return aqi_categories



# Drop rows with missing PM2.5 concentration values
df_PM = df_PM.dropna(subset=['PM2.5 Concentration (µg/m3)'])

# Extract PM2.5 concentrations
pm25_data = df_PM['PM2.5 Concentration (µg/m3)']

# Initialize the air quality system
air_quality_system = AirQualitySystem(pm25_data)

# Check air quality based on PM2.5 concentrations in the dataset
air_quality_categories = air_quality_system.check_air_quality()

# Ensure that the lengths match before adding the column
if len(pm25_data) == len(air_quality_categories):
    # Add Air Quality column to the DataFrame
    df_PM['Air Quality'] = air_quality_categories
else:
    print("Lengths of PM2.5 data and air quality categories do not match.")

def map_pollution_level(category_name):
    category_name = category_name.strip().lower()  # Convert to lowercase and remove whitespace
    for threshold, category in air_quality_system.aqi_categories.items():
        if category_name == category['name'].strip().lower():
            return category['pollution']
    print("Category name '{}' not found in aqi_categories dictionary.".format(category_name))
    return None

# Add a new column 'Air Pollution' based on 'Air Quality' column
df_PM['Air Pollution'] = df_PM['Air Quality'].apply(lambda x: map_pollution_level(x))

# Check if areas are near airports
df_PM['Near Airport'] = df_PM['Area Name'].isin(noms_aeroports_londres)
print(df_PM[df_PM['Near Airport'] == True])

print(df_PM[['Air Quality', 'Air Pollution']])

# Calcul de la fréquence d'apparition des niveaux de pollution
pollution_frequency = df_PM['Air Pollution'].value_counts().sort_index()

# Plot
plt.figure(figsize=(5, 3))
plt.bar(pollution_frequency.index, pollution_frequency.values)

# Étiquettes et titres
plt.xlabel('Niveau de pollution')
plt.ylabel('Fréquence')
plt.title('Fréquence d\'apparition des niveaux de pollution')

# Affichage du graphique
plt.xticks(pollution_frequency.index)
plt.show()

"""# Data exploration : Prédiction de cancer des poumons connaissant la qualité de l'air"""

import pandas as pd
import matplotlib.pyplot as plt

# Compter les occurrences de chaque valeur de la variable cible
target_counts = df_lung['Level'].value_counts(normalize=True)

# Créer un pie chart
plt.figure(figsize=(4, 4))
plt.pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Répartition du risque qu\'un patient développe un cancer des poumons')
plt.axis('equal')  # Assurer que le pie chart est dessiné en cercle
plt.tight_layout()  # Ajuster la mise en page pour éviter la superposition
plt.show()

# Compter les occurrences de chaque niveau de pollution de l'air
air_pollution_counts = df_lung['Air Pollution'].value_counts()

# Créer l'histogramme
plt.figure(figsize=(6, 4))
plt.bar(air_pollution_counts.index, air_pollution_counts, edgecolor='black')
plt.title('Répartition des niveaux de pollution de l\'air')
plt.xlabel('Niveau de pollution de l\'air')
plt.ylabel('Fréquence')
plt.tight_layout()
plt.show()

# Créer la figure et les sous-graphiques
fig, axs = plt.subplots(1, 2, figsize=(9, 4))

# Histogramme de la variable "Age"
axs[0].hist(df_lung['Age'], bins=20, edgecolor='black')
axs[0].set_title('Distribution d\'âge des patients')
axs[0].set_xlabel('Âge')
axs[0].set_ylabel('Fréquence')

# Diagramme circulaire de la variable "Genre"
gender_counts = df_lung['Gender'].value_counts()
axs[1].pie(gender_counts, labels=['Homme', 'Femme'], autopct='%1.1f%%', startangle=90)
axs[1].set_title('Répartition par genre')

# Afficher les graphiques
plt.tight_layout()
plt.show()

# Créer une table de contingence entre les niveaux de pollution de l'air et les niveaux de risque de cancer des poumons
cross_table = pd.crosstab(df_lung['Air Pollution'], df_lung['Level'])

# Plot stacked bar chart
cross_table.plot(kind='bar', stacked=True, figsize=(7, 4), color=['red', 'green', 'orange'])
plt.title('Corrélation entre le niveau de pollution de l\'air et le niveau de risque de cancer des poumons')
plt.xlabel('Niveau de pollution de l\'air')
plt.ylabel('Nombre de patients')
plt.xticks(rotation=0)
plt.legend(title='Niveau de risque')
plt.tight_layout()

# Afficher le graphique
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.graphics.mosaicplot import mosaic

# Créer une figure et une grille de sous-graphiques
fig, axs = plt.subplots(1, 2, figsize=(14, 6))

# Plot du premier graphique (box plot de l'âge par niveau de risque)
df_lung.boxplot(column='Age', by='Level', ax=axs[0], grid=False)
axs[0].set_title('Distribution de l\'âge pour chaque niveau de risque de cancer des poumons')
axs[0].set_xlabel('Niveau de risque de cancer des poumons')
axs[0].set_ylabel('Âge')
axs[0].tick_params(axis='x', rotation=0)
axs[0].tick_params(axis='y', rotation=0)

# Créer une table de contingence entre le genre et les niveaux de risque de cancer des poumons
gender_level_cross_table = pd.crosstab(df_lung['Gender'], df_lung['Level'])

# Plot du deuxième graphique (mosaïque plot de la corrélation entre le genre et le risque de cancer des poumons)
mosaic(gender_level_cross_table.stack(), ax=axs[1], title='Corrélation entre le genre et le risque de cancer des poumons')
axs[1].set_xlabel('Genre')
axs[1].set_ylabel('Niveau de risque de cancer des poumons')

# Ajuster la mise en page pour éviter la superposition
plt.tight_layout()

# Afficher les graphiques
plt.show()

"""# Prédiction de cancer des poumons connaissant la qualité de l'air

Considérant uniquement la pollution de l'air
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score

# Splitting data into features and target
X = df_lung[['Air Pollution']]
y = df_lung['Level']

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the parameter grid to search
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# Initialize the Random Forest classifier
rf_model = RandomForestClassifier(random_state=42)

# Initialize GridSearchCV
grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')

# Perform hyperparameter tuning
grid_search.fit(X_train, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_

# Make predictions
y_pred = best_rf_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Random Forest Classifier Accuracy:", accuracy)
print("Best Parameters:", grid_search.best_params_)

"""Considérant également l'âge et le genre"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score

# Splitting data into features and target
X = df_lung[['Air Pollution', 'Age', 'Gender']]
y = df_lung['Level']

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the parameter grid to search
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# Initialize the Random Forest classifier
rf_model2 = RandomForestClassifier(random_state=42)

# Initialize GridSearchCV
grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')

# Perform hyperparameter tuning
grid_search.fit(X_train, y_train)

# Get the best model
best_rf_model2 = grid_search.best_estimator_

# Make predictions
y_pred = best_rf_model2.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Random Forest Classifier Accuracy:", accuracy)
print("Best Parameters:", grid_search.best_params_)

"""# Utilisons le premier modèle pour prédire les risques d'avoir un cancer lorsque le PM2.5 est élevé"""

# Make predictions on the entire dataset
lung_risk_predictions = best_rf_model.predict(df_PM[['Air Pollution']])

# Add the predicted lung risk values as a new column to your DataFrame
df_PM['Lung Risk'] = lung_risk_predictions

# Print the DataFrame to verify the new column has been added
print(df_PM[['Air Quality', 'Air Pollution', 'Lung Risk']])

import matplotlib.pyplot as plt

# Define colors for different lung risk levels
colors = {
    'Low': 'green',
    'Medium': 'orange',
    'High': 'red',
}

# Map lung risk levels to corresponding colors
lung_risk_colors = [colors[risk] for risk in df_PM['Lung Risk']]

# Plotting
plt.figure(figsize=(10, 6))
plt.scatter(df_PM['Air Pollution'], df_PM['Lung Risk'], color=lung_risk_colors, label='Predicted Lung Risk')
plt.title('Relationship Between Lung Risk and Air Pollution')
plt.xlabel('Air Pollution')
plt.ylabel('Lung Risk')
plt.legend()
plt.grid(True)
plt.show()

"""# Analyse de la santé mentale selon le niveau de pollution de l'air"""

import pandas as pd
import matplotlib.pyplot as plt

# Afficher les valeurs uniques de la colonne "mentalhealth_survey"
mental_health_values = df_mental['mentalhealth_survey'].value_counts()

# Créer un pie chart
plt.figure(figsize=(4, 4))
plt.pie(mental_health_values, labels=mental_health_values.index, autopct='%1.1f%%', startangle=140)
plt.title('Répartition des réponses concernant la santé mentale')
plt.axis('equal')  # Assurer que le pie chart est dessiné en cercle
plt.tight_layout()  # Ajuster la mise en page pour éviter la superposition
plt.show()

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

# Encoder la variable catégorielle 'mentalhealth_survey'
df_mental['mentalhealth_survey_encoded'] = label_encoder.fit_transform(df_mental['mentalhealth_survey'])

import seaborn as sns

# Sélectionner les colonnes pertinentes pour l'analyse de corrélation
columns_of_interest = ['mentalhealth_survey_encoded',
                       'no2bcn_24h',
                       'no2bcn_12h',
                       'no2gps_24h',
                       'no2gps_12h',
                       'pm25bcn',
                       'BCμg',
                       ]

# Créer un sous-ensemble de données avec les colonnes sélectionnées
subset_data = df_mental[columns_of_interest]

# Calculer la matrice de corrélation
correlation_with_mental_health = subset_data.corr()['mentalhealth_survey_encoded'].dropna()
print(correlation_with_mental_health)

# Calculer la corrélation entre la variable encodée et les autres variables numériques
correlation_matrix = subset_data.corr()

labels = ['santé mentale',
          'NO2 Barcelone (24h)',
          'NO2 Barcelone (12h)',
          'NO2 GPS (24h)',
          'NO2 GPS (12h)',
          'PM2.5',
          'BC'
          ]

# Créer un heatmap pour visualiser les corrélations
plt.figure(figsize=(6, 5))
heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Heatmap de corrélation avec la santé mentale')

# Changer les labels des axes x et y
heatmap.set_xticklabels(labels, rotation=45)  # Rotation des labels de l'axe x pour une meilleure lisibilité
heatmap.set_yticklabels(labels, rotation=0)   # Pas de rotation pour les labels de l'axe y
plt.show()

"""Il n'y a pas de corrélation entre la santé mentale et le niveau de pollution"""
